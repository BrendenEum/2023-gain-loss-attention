---
title: "Parameter Recovery with Full Models"
output: html_notebook
---

# Preamble

```{r}
rm(list=ls())
set.seed(4)
library(tidyverse)
library(plotrix)
library(gridExtra)
library(ggpubr)
library(ggsci)
library(readr)
library(latex2exp)

#------------- Things you should edit at the start -------------
dataset = "e"
colors = list(Gain="Green4", Loss="Red3")
#---------------------------------------------------------------

codedir = getwd()
datadir = file.path(paste0("../../outputs/temp/model_fitting/", dataset))
cfrdir = file.path("../../../data/processed_data")
load(file.path(cfrdir, paste0(dataset, "cfr.RData")))
figdir = file.path("../../outputs/figures")
optdir = file.path("../plot_options/")
source(file.path(optdir, "GainLossColorPalette.R"))
source(file.path(optdir, "MyPlotOptions.R"))

Study1_folder = file.path(datadir, "Study1")
Study2_folder = file.path(datadir, "Study2")

Study1_subjects = unique(ecfr$subject[ecfr$studyN==1])
Study2_subjects = unique(ecfr$subject[ecfr$studyN==2])
```

# Load Data

```{r}
getData = function(folder, subjectList) {
  gain_compare = list()
  loss_compare = list()
  gain_posterior = list()
  loss_posterior = list()
  
  for (i in subjectList) {
    gain_compare[[i]] = read.csv(file = file.path(folder, paste0("Gain_modelComparison_", i, ".csv")))
    loss_compare[[i]] = read.csv(file = file.path(folder, paste0("Loss_modelComparison_", i, ".csv")))
    gain_posterior[[i]] = read.csv(file = file.path(folder, paste0("Gain_modelPosteriors_", i, ".csv")))
    loss_posterior[[i]] = read.csv(file = file.path(folder, paste0("Loss_modelPosteriors_", i, ".csv")))
    gain_compare[[i]]$subject = i
    loss_compare[[i]]$subject = i
    gain_posterior[[i]]$subject = i
    loss_posterior[[i]]$subject = i
  }
  gc = do.call("rbind", gain_compare)
  lc = do.call("rbind", loss_compare)
  gp = do.call("rbind", gain_posterior)
  lp = do.call("rbind", loss_posterior)
  
  gc$condition = "Gain"
  lc$condition = "Loss"
  gp$condition = "Gain"
  lp$condition = "Loss"
  compare = rbind(gc, lc)
  posteriors = rbind(gp, lp)
  
  compare$likelihood_fn = factor(
    compare$likelihood_fn,
    levels=c("aDDM_likelihood","AddDDM_likelihood","RaDDM_likelihood"),
    labels=c("aDDM","AddDDM","RaDDM")
  )
  posteriors$likelihood_fn = factor(
    posteriors$likelihood_fn,
    levels=c("aDDM_likelihood","AddDDM_likelihood","RaDDM_likelihood"),
    labels=c("aDDM","AddDDM","RaDDM")
  )
  
  return(list(compare = compare, posteriors = posteriors))
}

Study1 = getData(Study1_folder, Study1_subjects)
Study2 = getData(Study2_folder, Study2_subjects)
```

# Combine and clean the data for plotting

```{r}
# Study N
Study1$posteriors$study = 1
Study2$posteriors$study = 2
Study1$compare$study = 1
Study2$compare$study = 2

# Combine
.data = rbind(Study1$posteriors, Study2$posteriors)
.compare = rbind(Study1$compare, Study2$compare)

# Factor
.data$study = factor(.data$study, levels=c(1,2), labels=c("Study 1","Study 2"))
.compare$study = factor(.compare$study, levels=c(1,2), labels=c("Study 1","Study 2"))

# Get best fitting parameters for each subject
pdata = .data %>%
  group_by(study, subject, condition) %>%
  mutate(best_fitting = posterior==max(posterior))
pdata = pdata[pdata$best_fitting==1,]

# Check uniqueness based on study-subject-condition. There should only be 1 obs per. If not, then find the duplicated rows. Usually this is because theta=1, so all models are not distinguishable. If so, then go into the model comparison data and figure out which is the most likely model. Use that to determine which set of parameters to keep.
pdata$drop = 0
.duplicate_rows = duplicated(pdata[,c("study","subject","condition")]) | duplicated(pdata[,c("study","subject","condition")], fromLast=T)
.dups = pdata[.duplicate_rows,]
.dups_reference = .dups[ !duplicated(.dups[,c("study","subject","condition")]) , ]
.dups_reference
for (row in 1:nrow(.dups_reference)) {
  .study = .dups_reference$study[row]
  .subject = .dups_reference$subject[row]
  .condition = .dups_reference$condition[row]
  .compare_reference = .compare[.compare$study==.study & .compare$subject==.subject & .compare$condition==.condition,]
  .compare_best = .compare_reference$likelihood_fn[.compare_reference$posterior_sum == max(.compare_reference$posterior_sum)]
  
  ind = (pdata$study==.study & pdata$subject==.subject & pdata$condition==.condition)
  if (.compare_best=="aDDM") {pdata$drop[ind & pdata$likelihood_fn!="aDDM"] = 1}
  else if (.compare_best=="AddDDM") {pdata$drop[ind & pdata$likelihood_fn!="AddDDM"] = 1}
  else if (.compare_best=="RaDDM") {pdata$drop[ind & pdata$likelihood_fn!="RaDDM"] = 1}
  else {warning("Some study-subject-condition is repeated and there's no best-fitting model to help decide which parameters to report.")}
}

```

# Plot model comparison

```{r}
plt = ggplot(pdata, aes(x=likelihood_fn, y=posterior_sum)) +
    myPlot + 
    
    geom_hline(yintercept=.33, color="lightgrey") +
    geom_boxplot(aes(fill=condition), width=.4) +
    geom_dotplot(binaxis="y", stackdir="center", dotsize=1, fill="white") +
    
    labs(
      y = "Posterior Model Probability",
      x = "Model",
      fill = "Condition"
    ) +
    scale_y_continuous(breaks=c(0, .33, 1)) +
    facet_grid(rows=vars(condition), cols=vars(study)) +
    theme(
      strip.text.x = element_text(size = 20),
      strip.background = element_blank(),
      strip.text.y = element_blank(),
      panel.spacing = unit(1, "lines"),
      legend.position = c(.16,.88)
    )
plot(plt)
ggsave(file.path(figdir, "aDDM_modelComparison.pdf"), plot=plt, width = 12, height = 5)
```

